{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6e475e3d015d0dc",
   "metadata": {},
   "source": [
    "## Creación de un simple ChatBot que interactúa con llama 3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee809484ba7879e",
   "metadata": {},
   "source": [
    "### 1. Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c20561cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain==0.3.9\n",
      "  Downloading langchain-0.3.9-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain-core==0.3.21\n",
      "  Downloading langchain_core-0.3.21-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-ollama==0.2.0\n",
      "  Downloading langchain_ollama-0.2.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain==0.3.9)\n",
      "  Downloading PyYAML-6.0.2-cp312-cp312-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain==0.3.9)\n",
      "  Downloading SQLAlchemy-2.0.37-cp312-cp312-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain==0.3.9)\n",
      "  Downloading aiohttp-3.11.11-cp312-cp312-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain==0.3.9)\n",
      "  Downloading langchain_text_splitters-0.3.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.3.9)\n",
      "  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting numpy<3,>=1.26.2 (from langchain==0.3.9)\n",
      "  Downloading numpy-2.2.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain==0.3.9)\n",
      "  Downloading pydantic-2.10.5-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\l03564299\\appdata\\local\\miniconda3\\lib\\site-packages (from langchain==0.3.9) (2.32.3)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain==0.3.9)\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\l03564299\\appdata\\local\\miniconda3\\lib\\site-packages (from langchain-core==0.3.21) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\l03564299\\appdata\\local\\miniconda3\\lib\\site-packages (from langchain-core==0.3.21) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\l03564299\\appdata\\local\\miniconda3\\lib\\site-packages (from langchain-core==0.3.21) (4.12.2)\n",
      "Collecting ollama<1,>=0.3.0 (from langchain-ollama==0.2.0)\n",
      "  Downloading ollama-0.4.6-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.9)\n",
      "  Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.9)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.9)\n",
      "  Downloading attrs-24.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.9)\n",
      "  Downloading frozenlist-1.5.0-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.9)\n",
      "  Downloading multidict-6.1.0-cp312-cp312-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.9)\n",
      "  Downloading propcache-0.2.1-cp312-cp312-win_amd64.whl.metadata (9.5 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.9)\n",
      "  Downloading yarl-1.18.3-cp312-cp312-win_amd64.whl.metadata (71 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\l03564299\\appdata\\local\\miniconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core==0.3.21) (2.1)\n",
      "INFO: pip is looking at multiple versions of langchain-text-splitters to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain==0.3.9)\n",
      "  Downloading langchain_text_splitters-0.3.4-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_text_splitters-0.3.3-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_text_splitters-0.3.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<0.2.0,>=0.1.17->langchain==0.3.9)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain==0.3.9)\n",
      "  Downloading orjson-3.10.14-cp312-cp312-win_amd64.whl.metadata (42 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.17->langchain==0.3.9)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<0.2.0,>=0.1.17->langchain==0.3.9)\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain==0.3.9)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3.0.0,>=2.7.4->langchain==0.3.9)\n",
      "  Downloading pydantic_core-2.27.2-cp312-cp312-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\l03564299\\appdata\\local\\miniconda3\\lib\\site-packages (from requests<3,>=2->langchain==0.3.9) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\l03564299\\appdata\\local\\miniconda3\\lib\\site-packages (from requests<3,>=2->langchain==0.3.9) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\l03564299\\appdata\\local\\miniconda3\\lib\\site-packages (from requests<3,>=2->langchain==0.3.9) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\l03564299\\appdata\\local\\miniconda3\\lib\\site-packages (from requests<3,>=2->langchain==0.3.9) (2024.12.14)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain==0.3.9)\n",
      "  Downloading greenlet-3.1.1-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.9)\n",
      "  Downloading anyio-4.8.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.9)\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting sniffio (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.9)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.9)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Downloading langchain-0.3.9-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 0.5/1.0 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.0/1.0 MB 3.0 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.3.21-py3-none-any.whl (409 kB)\n",
      "Downloading langchain_ollama-0.2.0-py3-none-any.whl (14 kB)\n",
      "Downloading aiohttp-3.11.11-cp312-cp312-win_amd64.whl (437 kB)\n",
      "Downloading langchain_text_splitters-0.3.2-py3-none-any.whl (25 kB)\n",
      "Downloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
      "Downloading numpy-2.2.1-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.0/12.6 MB 5.6 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 2.1/12.6 MB 5.3 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 3.1/12.6 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 4.2/12.6 MB 5.0 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 5.2/12.6 MB 5.1 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 6.3/12.6 MB 5.1 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 7.6/12.6 MB 5.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.7/12.6 MB 5.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.7/12.6 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.0/12.6 MB 5.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.1/12.6 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 5.1 MB/s eta 0:00:00\n",
      "Downloading ollama-0.4.6-py3-none-any.whl (13 kB)\n",
      "Downloading pydantic-2.10.5-py3-none-any.whl (431 kB)\n",
      "Downloading pydantic_core-2.27.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   -------------------------- ------------- 1.3/2.0 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 6.1 MB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0.2-cp312-cp312-win_amd64.whl (156 kB)\n",
      "Downloading SQLAlchemy-2.0.37-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 0.8/2.1 MB 4.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.6/2.1 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 3.8 MB/s eta 0:00:00\n",
      "Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading attrs-24.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading frozenlist-1.5.0-cp312-cp312-win_amd64.whl (51 kB)\n",
      "Downloading greenlet-3.1.1-cp312-cp312-win_amd64.whl (299 kB)\n",
      "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Downloading multidict-6.1.0-cp312-cp312-win_amd64.whl (28 kB)\n",
      "Downloading orjson-3.10.14-cp312-cp312-win_amd64.whl (133 kB)\n",
      "Downloading propcache-0.2.1-cp312-cp312-win_amd64.whl (44 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading yarl-1.18.3-cp312-cp312-win_amd64.whl (90 kB)\n",
      "Downloading anyio-4.8.0-py3-none-any.whl (96 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: tenacity, sniffio, PyYAML, pydantic-core, propcache, orjson, numpy, multidict, h11, greenlet, frozenlist, attrs, annotated-types, aiohappyeyeballs, yarl, SQLAlchemy, requests-toolbelt, pydantic, httpcore, anyio, aiosignal, httpx, aiohttp, ollama, langsmith, langchain-core, langchain-text-splitters, langchain-ollama, langchain\n",
      "Successfully installed PyYAML-6.0.2 SQLAlchemy-2.0.37 aiohappyeyeballs-2.4.4 aiohttp-3.11.11 aiosignal-1.3.2 annotated-types-0.7.0 anyio-4.8.0 attrs-24.3.0 frozenlist-1.5.0 greenlet-3.1.1 h11-0.14.0 httpcore-1.0.7 httpx-0.27.2 langchain-0.3.9 langchain-core-0.3.21 langchain-ollama-0.2.0 langchain-text-splitters-0.3.2 langsmith-0.1.147 multidict-6.1.0 numpy-2.2.1 ollama-0.4.6 orjson-3.10.14 propcache-0.2.1 pydantic-2.10.5 pydantic-core-2.27.2 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.0.0 yarl-1.18.3\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain==0.3.9 langchain-core==0.3.21 langchain-ollama==0.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3d2707c728a2d18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T19:50:56.686095Z",
     "start_time": "2024-11-21T19:50:56.060193Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddf26fb11c3b0d",
   "metadata": {},
   "source": [
    "## 2. Large language model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ab209c5e57c5d3",
   "metadata": {},
   "source": [
    "Hay diferentes modelos que se pueden usar. La mayoría necesita un \"API KEY\":\n",
    "\n",
    "ChatOpenAI, ChatAnthropic, ChatVertexAI, ChatCohere, ChatNVIDIA, ChatGroq, ChatMistralAI\n",
    "\n",
    "Existen otros modelos en la plataforma HUGGINGFACE.\n",
    "\n",
    "Para la mayoría de los modelos hay que definir una variable de entorno:\n",
    "\n",
    "------------------------------------------------------------------------------\n",
    "import getpass\n",
    "\n",
    "import os\n",
    "\n",
    "export OPENAI_API_KEY=\"...\"\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4\")\n",
    "\n",
    "------------------------------------------------------------------------------\n",
    "\n",
    "Usando Ollama en local no es necesario definir variables de entorno. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T19:51:29.667040Z",
     "start_time": "2024-11-21T19:51:29.646351Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "local_llm = 'llama3.2'\n",
    "llm = ChatOllama(model=local_llm, temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ca09143b4658d2",
   "metadata": {},
   "source": [
    "Algunos de los parámetros más importantes que se deben/pueden especificar:\n",
    "\n",
    "-**model**: el nombre del modelo específico que se quiere usar (por ejemplo, para ChatOpenAI puede ser \"gpt-3.5-turbo\" o \"gpt-4\")\n",
    "\n",
    "**temperature**: controla la aleatoriedad de la respuesta (y la capacidad \"generativa\"), el valor mínimo es 0 (muy baja aleatoriedad y creatividad).\n",
    "\n",
    "**timeout**: el máximo tiempo de espera para obtener la respuesta\n",
    "\n",
    "**max_tokens**: es un número que limita el valor máximo de palabra y puntuación en la respuesta.\n",
    "\n",
    "**api_key**: el api key del usuario\n",
    "\n",
    "No todos los modelos admiten los mismos parámetros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc276cd940e2d89e",
   "metadata": {},
   "source": [
    "Métodos clave del modelo de chat:\n",
    "\n",
    "-**invoke**: El método principal para interactuar con un modelo de chat. Acepta una lista de mensajes como entrada y devuelve una lista de mensajes como salida.\n",
    "\n",
    "-**stream**: Un método que permite transmitir la salida de un modelo de chat a medida que se genera.\n",
    "\n",
    "-**batch**: Un método que permite agrupar varias solicitudes a un modelo de chat para su procesamiento eficiente.\n",
    "\n",
    "-**bind_tools**: Un método que permite vincular una herramienta a un modelo de chat para su uso en el contexto de ejecución del modelo.\n",
    "\n",
    "-**with_structured_output**: Un envoltorio alrededor del método invoke para modelos que admiten natively salida estructurada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cb68249f90d9421",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T19:56:11.458246Z",
     "start_time": "2024-11-21T19:56:06.271833Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hola se traduce a \"Hello\" en inglés.', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-01-15T17:59:53.4482696Z', 'done': True, 'done_reason': 'stop', 'total_duration': 16969223600, 'load_duration': 6360893900, 'prompt_eval_count': 35, 'prompt_eval_duration': 8080000000, 'eval_count': 14, 'eval_duration': 2509000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-1f00e1e0-1111-418a-8265-7b9dfc0468ec-0', usage_metadata={'input_tokens': 35, 'output_tokens': 14, 'total_tokens': 49})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages= 'Hola, traduce al inglés: hola'\n",
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c4a70a22679655",
   "metadata": {},
   "source": [
    "### 3. Mensajes\n",
    "\n",
    "Un mensaje suele consistir en las siguientes piezas de información:\n",
    "\n",
    "-**Rol**: El rol del mensaje (por ejemplo, \"usuario\", \"asistente\").\n",
    "\n",
    "-**Contenido**: El contenido del mensaje (por ejemplo, texto, datos multimodales).\n",
    "\n",
    "-**Metadatos adicionales**: id, nombre, uso de tokens y otros metadatos específicos del modelo.\n",
    "\n",
    "Rol\n",
    "Los roles se utilizan para distinguir entre diferentes tipos de mensajes en una conversación y ayudar al modelo de chat a entender cómo responder a una secuencia determinada de mensajes.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2e7721f8ee3daea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T19:59:40.630742Z",
     "start_time": "2024-11-21T19:59:40.627809Z"
    }
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"Translate the following from english to spanish\"),\n",
    "    HumanMessage(content=\"Hi\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b40ea6efd755e7",
   "metadata": {},
   "source": [
    "Se puede usar un \"parser\" para escribir la respuesta sin metedatos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e856039318cc1f4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T20:01:04.397393Z",
     "start_time": "2024-11-21T20:01:03.205263Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hola'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = StrOutputParser()\n",
    "result = llm.invoke(messages)\n",
    "parser.invoke(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8226eaac7f614b7",
   "metadata": {},
   "source": [
    "Se pueden juntar el modelo y el parser en una \"chain\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e77666759cdde8df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T20:01:25.164581Z",
     "start_time": "2024-11-21T20:01:24.358762Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hola'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = llm | parser\n",
    "chain.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8417bbf15244e2f6",
   "metadata": {},
   "source": [
    "**Temperature**\n",
    "\n",
    "Repetimos 5 veces la pregunta \"Escribe un color cualquiera\" y analizamos las respuestas para diferentes valores del parámetro \"temperature\". Para un valor de temperature=0:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88a691e0fd7d8349",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T20:13:24.537977Z",
     "start_time": "2024-11-21T20:13:18.876665Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El color que te voy a escribir es... **azul**.\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "El color que te voy a escribir es... **azul**.\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "El color que te voy a escribir es... **azul**.\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "El color que te voy a escribir es... **azul**.\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "El color que te voy a escribir es... **azul**.\n",
      "------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "messages = 'Hola, escribe un color cualquiera'\n",
    "llm = ChatOllama(model=local_llm, temperature=0)\n",
    "chain = llm | parser\n",
    "for i in range(5):\n",
    "    print(chain.invoke(messages))\n",
    "    print('------------------------------------------------\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10e6899eab795f",
   "metadata": {},
   "source": [
    "Para el valor temperature=1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e78d574fa7e94211",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T20:14:35.435018Z",
     "start_time": "2024-11-21T20:14:26.332131Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El color que te escribiré es... AZUL.\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "El color que te voy a elegir es... azul. ¿Te gusta?\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "El color azul.\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "Hermosa pregunta!\n",
      "\n",
      "El color que elegir... ¡cómo puedo decidir?\n",
      "\n",
      "Mi elección es... **azul cielo**. Un color fresco y alegre, perfecto para representar la calidez y la serenidad de un día soleado en el parque.\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "El color que he elegido es... \n",
      "\n",
      "**Marrón cálido**\n",
      "\n",
      "Espero que te guste. ¿Quieres que escriba otro color?\n",
      "------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "messages = \"Hola, escribe un color cualquiera\"\n",
    "llm = ChatOllama(model=local_llm, temperature=1)\n",
    "chain = llm | parser\n",
    "for i in range(5):\n",
    "    print(chain.invoke(messages))\n",
    "    print('------------------------------------------------\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648613d13e4eb6db",
   "metadata": {},
   "source": [
    "**top-k y top-P**\n",
    "\n",
    "Al igual que la temperatura, los parámetros top-K y top-P también se utilizan para controlar la diversidad de la salida del modelo.\n",
    "\n",
    "Top-K es un número entero positivo que define la cantidad de tokens más probables de los cuales seleccionar el token de salida. Un top-K de 1 selecciona un solo token.\n",
    "\n",
    "Top-P define el umbral de probabilidad que, una vez excedido de forma acumulativa, los tokens dejan de ser seleccionados como candidatos. Un top-P de 0 es equivalente típicamente al top K con k=1, y un top-P de 1 selecciona típicamente todos los tokens en el vocabulario del modelo.\n",
    "\n",
    "Ejecute este ejemplo varias veces, cambie la configuración y observe el cambio en la salida.\n",
    " \n",
    "- top k =64  top_p = 0.95\n",
    "\n",
    "- top k=1 top_p =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "520ba039b748d467",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T20:26:17.419229Z",
     "start_time": "2024-11-21T20:25:42.739272Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**The Whispering Woods**\n",
      "\n",
      "Whiskers, the curious cat, stood at the threshold of her cozy home, paw on the doorframe, as if hesitating to leave. Her tail twitched with excitement and caution, like two antennae tuning into the whispers of the universe. The moon cast a silver glow outside, illuminating the windowsill where the morning sunlight had left its mark.\n",
      "\n",
      "Without warning, Whiskers sprang from the comfort of her doorstep, tail in tow, as if swept by an unseen force. She padded silently across the porch and vanished into the heart of the Whispering Woods.\n",
      "\n",
      "The forest was alive with the secrets it kept within its ancient boughs and whispering leaves. The air vibrated with whispers – murmurs from creatures great and small – each sharing tales of long-forgotten deeds, love stories, and mysteries veiled in mist. Whiskers followed the siren's call, her ears perked up like satellite dishes tuning into a hidden frequency.\n",
      "\n",
      "As she wandered deeper, the trees grew taller and closer together, their branches intertwined above her head. Shafts of moonlight broke through the canopy, casting dappled shadows on the forest floor. Whiskers navigated with an air of feline confidence, though every now and then, she'd pause to listen and inhale.\n",
      "\n",
      "She stumbled upon a clearing where creatures from dreams gathered. A great stag stood sentinel, his antlers shining in moonlight, while a fox, once mortal, now a shape-shifter's friend, danced alongside a tiny fairy no bigger than Whiskers' paw. They welcomed her with whispers of gratitude and shared tales of their adventures.\n",
      "\n",
      "A breeze rustled the leaves as a fabled cat appeared before her – Purrfectia, an ancient matriarch whose whiskers held secrets of the past and eyes that shone like stars on moonlit nights. The elder cat regarded Whiskers, as if sizing up the fledgling's bravery.\n",
      "\n",
      "Whiskers stood poised, ears erect, sensing a gateway to knowledge hidden within these whispers and stories. Without needing words, Purrfectia shared with a mere touch of her whisker that this forest held an ancient secret – the one hidden path that led beyond mortal limits. The feline companion gifted Whiskers a whispered password: _Echoes of Eternity_.\n",
      "\n",
      "Within seconds, Whiskers felt transformed, as if the whispers had imbued her with secrets of old. Her eyes now shone like moonlit shadows on stone walls, knowing she was bound to keep these whispers hidden – sharing them when they were needed by those brave enough to search.\n",
      "\n",
      "When dawn crept over the horizon, painting the forest in hues of sunrise and golden twilight, Whiskers padded back to her doorstep, silent as a ghost. As if awakening from a dream, she stepped onto the porch, looked around curiously, then took a moment to smile.\n",
      "\n",
      "Her home beckoned once more, but now her heart was no longer whole – only half-satisfied by what lay hidden within Whispering Woods and the secrets shared with her as an honored guest of the unknown.\n"
     ]
    }
   ],
   "source": [
    "messages = \"You are a creative writer. Write a short story about a cat who goes on an adventure\"\n",
    "llm = ChatOllama(model=local_llm, temperature=1, top_k=64, top_p=0.95)\n",
    "chain = llm | parser\n",
    "print(chain.invoke(messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c29fb6084bd0966",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T20:27:29.516198Z",
     "start_time": "2024-11-21T20:26:39.268207Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**The Whiskered Wanderer**\n",
      "\n",
      "In the sleepy town of Willowdale, where sunbeams danced through the windows and dust motes waltzed in the air, a sleek black cat named Midnight prowled the streets. Her eyes gleamed like polished onyx as she padded silently from house to house, searching for adventure.\n",
      "\n",
      "Midnight's owner, an elderly lady named Mrs. Jenkins, had grown fond of her mischievous ways and often left treats and toys scattered about the house. But tonight, Midnight yearned for something more – a taste of freedom, a dash of excitement.\n",
      "\n",
      "As she slipped out into the night air, the world came alive around her. Fireflies twinkled like tiny lanterns, casting a magical glow over the cobblestone streets. The scent of blooming flowers wafted on the breeze, enticing Midnight to explore further.\n",
      "\n",
      "She padded through alleys and side streets, weaving past sleeping dogs and snoring cats. Her ears perked up at every sound – a chirping cricket, a hooting owl, or the distant rumble of thunder. With each step, Midnight felt her whiskers twitching with anticipation.\n",
      "\n",
      "As she wandered deeper into the town, Midnight stumbled upon a hidden path she had never seen before. The air grew thick with the scent of damp earth and moss, and the trees seemed to lean in, as if sharing a secret. Without hesitation, Midnight followed the winding trail, her paws padding softly on the forest floor.\n",
      "\n",
      "The trees grew taller and closer together here, casting dappled shadows across the ground. Midnight's eyes adjusted to the dim light, and she spotted a glint of silver in the distance – a small stream, its surface reflecting the starry sky above.\n",
      "\n",
      "Without hesitation, Midnight plunged into the water, sending ripples through the calm surface. She paddled with her front paws, feeling the cool liquid envelop her fur. As she swam, the world around her dissolved into a kaleidoscope of colors and sounds – the chirping of crickets, the rustling of leaves, and the gentle lapping of water against her ears.\n",
      "\n",
      "For a moment, Midnight forgot about Mrs. Jenkins, the treats, and the comforts of home. She was free, untethered by the constraints of everyday life. The stream became her own personal highway, carrying her to unknown destinations and hidden wonders.\n",
      "\n",
      "As she swam further downstream, Midnight spotted a family of otters playing in the shallows. They welcomed her with open arms – or rather, open paws – and invited her to join their game of chase-the-fish. Midnight laughed, a throaty purr rumbling deep within her chest, as she chased after the slippery creatures.\n",
      "\n",
      "Eventually, the sun began to rise, casting a golden glow over the forest. Midnight reluctantly bid farewell to her new friends and continued downstream, following the stream until it merged with a larger river.\n",
      "\n",
      "As she emerged from the water, shaking off excess droplets, Midnight spotted a majestic castle rising above the trees – its towers reaching for the clouds like giant's fists. The wind whispered secrets in her ear, and Midnight felt an inexplicable pull towards the ancient structure.\n",
      "\n",
      "Without hesitation, she padded up the winding path, her tail twitching with excitement. As she reached the entrance, a pair of stone lions gazed down at her, their eyes gleaming with a knowing intelligence. Midnight pushed open the massive doors, and a warm light spilled out, bathing her in its radiance.\n",
      "\n",
      "Inside, she discovered a labyrinthine library filled with ancient tomes and mysterious artifacts. The air was thick with the scent of parchment and knowledge. Midnight's whiskers twitched as she explored the shelves, uncovering secrets hidden within the pages of forgotten books.\n",
      "\n",
      "As the sun climbed higher in the sky, casting long shadows across the castle walls, Midnight realized it was time to return home. She bid farewell to the library, promising to keep its secrets safe, and began her journey back through the forest.\n",
      "\n",
      "The stream had changed course overnight, but Midnight navigated its twists and turns with ease, guided by the memories of her adventure. As she emerged from the trees, Mrs. Jenkins welcomed her with open arms, a warm smile on her face.\n",
      "\n",
      "\"Midnight, where have you been?\" she asked, scratching behind the cat's ears.\n",
      "\n",
      "Midnight purred contentedly, her eyes gleaming with a secret knowledge. She knew that some adventures were meant to remain hidden, but others – like this one – would stay with her forever, etched in the whispers of her whiskers and the beat of her heart.\n"
     ]
    }
   ],
   "source": [
    "messages = \"You are a creative writer. Write a short story about a cat who goes on an adventure\"\n",
    "llm = ChatOllama(model=local_llm, temperature=1, top_k=1, top_p=0)\n",
    "chain = llm | parser\n",
    "print(chain.invoke(messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a7d135ca719b6130",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T20:30:45.480944Z",
     "start_time": "2024-11-21T20:29:54.503023Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**The Whiskered Wanderer**\n",
      "\n",
      "In the sleepy town of Willowdale, where sunbeams danced through the windows and dust motes waltzed in the air, a sleek black cat named Midnight prowled the streets. Her eyes gleamed like polished onyx as she padded silently from house to house, searching for adventure.\n",
      "\n",
      "Midnight's owner, an elderly lady named Mrs. Jenkins, had grown fond of her mischievous ways and often left treats and toys scattered about the house. But tonight, Midnight yearned for something more – a taste of freedom, a dash of excitement.\n",
      "\n",
      "As she slipped out into the night air, the world came alive around her. Fireflies twinkled like tiny lanterns, casting a magical glow over the cobblestone streets. The scent of blooming flowers wafted on the breeze, enticing Midnight to explore further.\n",
      "\n",
      "She padded through alleys and side streets, weaving past sleeping dogs and snoring cats. Her ears perked up at every sound – a chirping cricket, a hooting owl, or the distant rumble of thunder. With each step, Midnight felt her whiskers twitching with anticipation.\n",
      "\n",
      "As she wandered deeper into the town, Midnight stumbled upon a hidden path she had never seen before. The air grew thick with the scent of damp earth and moss, and the trees seemed to lean in, as if sharing a secret. Without hesitation, Midnight followed the winding trail, her paws padding softly on the forest floor.\n",
      "\n",
      "The trees grew taller and closer together here, casting dappled shadows across the ground. Midnight's eyes adjusted to the dim light, and she spotted a glint of silver in the distance – a small stream, its surface reflecting the starry sky above.\n",
      "\n",
      "Without hesitation, Midnight plunged into the water, sending ripples through the calm surface. She paddled with her front paws, feeling the cool liquid envelop her fur. As she swam, the world around her dissolved into a kaleidoscope of colors and sounds – the chirping of crickets, the rustling of leaves, and the gentle lapping of water against her ears.\n",
      "\n",
      "For a moment, Midnight forgot about Mrs. Jenkins, the treats, and the comforts of home. She was free, untethered by the constraints of everyday life. The stream became her own personal highway, carrying her to unknown destinations and hidden wonders.\n",
      "\n",
      "As she swam further downstream, Midnight spotted a family of otters playing in the shallows. They welcomed her with open arms – or rather, open paws – and invited her to join their game of chase-the-fish. Midnight laughed, a throaty purr rumbling deep within her chest, as she chased after the slippery creatures.\n",
      "\n",
      "Eventually, the sun began to rise, casting a golden glow over the forest. Midnight reluctantly bid farewell to her new friends and continued downstream, following the stream until it merged with a larger river.\n",
      "\n",
      "As she emerged from the water, shaking off excess droplets, Midnight spotted a majestic castle rising above the trees – its towers reaching for the clouds like giant's fists. The wind whispered secrets in her ear, and Midnight felt an inexplicable pull towards the ancient structure.\n",
      "\n",
      "Without hesitation, she padded up the winding path, her tail twitching with excitement. As she reached the entrance, a pair of stone lions gazed down at her, their eyes gleaming with a knowing intelligence. Midnight pushed open the massive doors, and a warm light spilled out, bathing her in its radiance.\n",
      "\n",
      "Inside, she discovered a labyrinthine library filled with ancient tomes and mysterious artifacts. The air was thick with the scent of parchment and knowledge. Midnight's whiskers twitched as she explored the shelves, uncovering secrets hidden within the pages of forgotten books.\n",
      "\n",
      "As the sun climbed higher in the sky, casting long shadows across the castle walls, Midnight realized it was time to return home. She bid farewell to the library, promising to keep its secrets safe, and began her journey back through the forest.\n",
      "\n",
      "The stream had changed course overnight, but Midnight navigated its twists and turns with ease, guided by the memories of her adventure. As she emerged from the trees, Mrs. Jenkins welcomed her with open arms, a warm smile on her face.\n",
      "\n",
      "\"Midnight, where have you been?\" she asked, scratching behind the cat's ears.\n",
      "\n",
      "Midnight purred contentedly, her eyes gleaming with a secret knowledge. She knew that some adventures were meant to remain hidden, but others – like this one – would stay with her forever, etched in the whispers of her whiskers and the beat of her heart.\n"
     ]
    }
   ],
   "source": [
    "messages = \"You are a creative writer. Write a short story about a cat who goes on an adventure\"\n",
    "llm = ChatOllama(model=local_llm, temperature=1, top_k=5, top_p=0)\n",
    "chain = llm | parser\n",
    "print(chain.invoke(messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2feecf481711e508",
   "metadata": {},
   "source": [
    "## 2. Prompt templates\n",
    "\n",
    "Si se quieren hacer preguntas siempre del mismo tipo, dando las mismas instrucciones al sistema, se pueden definir \"prompt templates\", que pueden contener variables, definidas entre {}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8328963faa7b4f92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T20:05:13.245816Z",
     "start_time": "2024-11-21T20:05:13.242267Z"
    }
   },
   "outputs": [],
   "source": [
    "system_template = \"Translate the following into {language}, write only the translated word:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7997d3031ff3b160",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T20:53:20.103655Z",
     "start_time": "2024-11-21T20:53:20.100003Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "931e2e513973b3a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T20:53:21.633014Z",
     "start_time": "2024-11-21T20:53:21.618308Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Translate the following into italian, write only the translated word:', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOllama(model=local_llm, temperature=0)\n",
    "result = prompt_template.invoke({\"language\": \"italian\", \"text\": \"hi\"})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c3782042470db8cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T20:53:25.711320Z",
     "start_time": "2024-11-21T20:53:25.706511Z"
    }
   },
   "outputs": [],
   "source": [
    "chain = prompt_template | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5fb8794710829214",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T20:53:32.121166Z",
     "start_time": "2024-11-21T20:53:27.501663Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ciao'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"language\": \"italian\", \"text\": \"hi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15ff91bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"language\": \"korean\", \"text\": \"hi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "84ee819fef100606",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T20:53:47.718716Z",
     "start_time": "2024-11-21T20:53:45.841225Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why did the cat join a band?\\n\\nBecause it wanted to be the purr-cussionist!'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", \"You are a helpful assistant\"),\n",
    "    (\"user\", \"Tell me a joke about {topic}\")\n",
    "])\n",
    "\n",
    "chain = prompt_template | llm | parser\n",
    "chain.invoke({\"topic\": \"cats\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc3e3a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
